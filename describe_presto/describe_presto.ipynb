{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Ingest - Ingest data using SQL query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "import nuclio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nuclio config kind = \"job\"\n",
    "%nuclio config spec.build.baseImage = \"mlrun/mlrun\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%nuclio cmd -c\n",
    "pip install --no-cache-dir git+https://github.com/v3io/PyHive.git@v0.6.999 \n",
    "pip install sqlalchemy==1.3.11\n",
    "pip install PyMySQL==0.9.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyhive\n",
    "from sqlalchemy.engine import create_engine\n",
    "from mlrun.execution import MLClientCtx\n",
    "\n",
    "\n",
    "def get_big_dataset_meta(\n",
    "    context: MLClientCtx,\n",
    "    database_url: str,\n",
    "    table_name: str,\n",
    ") -> None:\n",
    "\n",
    "    \"\"\"\n",
    "    Update big dataset object attributes/metadata by using presto engine\n",
    "\n",
    "    this method will edit or add metadata to a dataset object\n",
    "    \n",
    "    :param sql_query:         the sql query used to retrieve the data\n",
    "    :param database_url:      database connection URL\n",
    "    :param table_name:        table name to query\n",
    "    \"\"\"\n",
    "\n",
    "    engine = create_engine(database_url)\n",
    "\n",
    "    preview_sql = \"\"\"SELECT * FROM {} LIMIT 100\"\"\".format(table_name)\n",
    "    header_schema_sql = \"\"\"SHOW COLUMNS FROM {}\"\"\".format(table_name)\n",
    "\n",
    "    preview = pd.read_sql(preview_sql, engine)\n",
    "    header_schema = pd.read_sql(header_schema_sql, engine)\n",
    "    #stats = pd.read_sql(stats_sql, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mlconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import mlconf\n",
    "import os\n",
    "mlconf.dbpath = mlconf.dbpath or 'http://mlrun-api:8080'\n",
    "mlconf.artifact_path = mlconf.artifact_path or f'{os.environ[\"HOME\"]}/artifacts'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mount_secret(\n",
    "    secret_name, volume_mount_path, volume_name='secret', items=None\n",
    "):\n",
    "    def _mount_secret(task):\n",
    "        from kubernetes import client as k8s_client\n",
    "        vol = k8s_client.V1SecretVolumeSource(secret_name=secret_name, items=items)\n",
    "        return task.add_volume(\n",
    "            k8s_client.V1Volume(name=volume_name, secret=vol)\n",
    "        ).add_volume_mount(\n",
    "            k8s_client.V1VolumeMount(mount_path=volume_mount_path, name=volume_name)\n",
    "        )\n",
    "    return _mount_secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import code_to_function, NewTask\n",
    "import os\n",
    "\n",
    "fn = code_to_function(name=\"sql_to_file\",\n",
    "                      handler=\"sql_to_file\",\n",
    "                      description=\"SQL To File - Ingest data using SQL query\",\n",
    "                      categories=[\"data-prep\"],\n",
    "                      labels={\"author\": \"adih\"})\n",
    "\n",
    "if \"V3IO_ACCESS_KEY\" in list(os.environ):\n",
    "    fn.apply(mount_secret(secret_name='presto-tls',\n",
    "                        volume_mount_path= '/var/run/iguazio/secrets/'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.export('function.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading from a public MySQL DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mysql_url = 'mysql+pymysql://rfamro@mysql-rfam-public.ebi.ac.uk:4497/Rfam'\n",
    "mysql_query = 'select rfam_acc,rfam_id,auto_wiki,description,author,seed_source FROM family'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import NewTask, run_local\n",
    "\n",
    "sql_task = NewTask(name='sql',\n",
    "                   handler=sql_to_file,\n",
    "                   params={'sql_query': mysql_query,\n",
    "                           'database_url': mysql_url})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_func = run_local(sql_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run it on a cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.run(sql_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL query from Iguazio Key Value via Presto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to create a table and set the sql_table path accordingly. <br>\n",
    "you can find an example of creating such table in https://github.com/v3io/tutorials/blob/master/data-ingestion-and-preparation/basic-data-ingestion-and-preparation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "import os\n",
    "sql_table = os.path.join('v3io.users.\"'+str(os.getenv('V3IO_USERNAME'))+'/examples/stocks_tab\"')\n",
    "sql_query_string = 'select * from '+sql_table+\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql select * from $sql_table limit 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_task = NewTask(name='sql', \n",
    "                   handler=sql_to_file,\n",
    "                   params={'sql_query': sql_query_string,\n",
    "                          'database_url': os.getenv('DATABASE_URL')}\n",
    "                          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_func = run_local(sql_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.run(sql_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}